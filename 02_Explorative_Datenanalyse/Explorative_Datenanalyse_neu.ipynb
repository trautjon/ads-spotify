{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 1: Daten in die SQL-Datenbank importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erforderliche Pakete installieren\n",
    "pip install pandas sqlalchemy pymysql openpyxl seaborn cartopy\n",
    "pip install -U scikit-learn\n",
    "!pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Sensible Daten aus Umgebungsvariablen lesen\n",
    "db_user = os.getenv('DB_USER', 'root')\n",
    "db_password = os.getenv('DB_PASSWORD', 'example')\n",
    "db_host = os.getenv('DB_HOST', 'localhost')\n",
    "db_name = os.getenv('DB_NAME', 'spotify_data')\n",
    "\n",
    "# Verbindung zur MySQL-Datenbank herstellen\n",
    "engine = create_engine(f'mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}')\n",
    "\n",
    "# Ordnerpfad mit Excel-Dateien (entweder als rohe Zeichenfolge oder mit doppelten Backslashes)\n",
    "folder_path = r'/Users/bavaarde/ads-spotify/2024-05-18'\n",
    "# oder\n",
    "# folder_path = 'C:\\\\applied_data_science\\\\gruppen_projekt\\\\ads-spotify\\\\ads-spotify\\\\2024-04-27'\n",
    "\n",
    "# Funktion, um SQLAlchemy-Datentypen basierend auf Pandas-Datentypen zu bestimmen\n",
    "def map_dtype(dtype):\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return Integer()\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return Float()\n",
    "    else:\n",
    "        return String(255)  # Standard-Stringlänge 255\n",
    "\n",
    "# Alle Excel-Dateien im Ordner durchgehen\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Excel-Datei in ein DataFrame laden\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Tabellenname basierend auf dem Dateinamen (ohne Erweiterung)\n",
    "        table_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Metadaten und Tabelle definieren\n",
    "        metadata = MetaData()\n",
    "        columns = []\n",
    "        for col_name, dtype in zip(df.columns, df.dtypes):\n",
    "            col_type = map_dtype(dtype)\n",
    "            columns.append(Column(col_name, col_type))\n",
    "        \n",
    "        table = Table(table_name, metadata, *columns)\n",
    "        \n",
    "        try:\n",
    "            # Tabelle in der Datenbank erstellen\n",
    "            metadata.create_all(engine)\n",
    "            \n",
    "            # Daten in die Tabelle einfügen\n",
    "            df.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "            print(f\"Tabelle '{table_name}' erfolgreich erstellt und Daten importiert.\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"Fehler beim Erstellen der Tabelle '{table_name}': {e}\")\n",
    "\n",
    "print(\"Vorgang abgeschlossen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 2: Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "# Sensible Daten aus Umgebungsvariablen lesen\n",
    "db_user = os.getenv('DB_USER', 'root')\n",
    "db_password = os.getenv('DB_PASSWORD', 'example')\n",
    "db_host = os.getenv('DB_HOST', 'localhost')\n",
    "db_name = os.getenv('DB_NAME', 'spotify_data')\n",
    "\n",
    "# Verbindung zur MySQL-Datenbank herstellen\n",
    "engine = create_engine(f'mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}')\n",
    "\n",
    "# Inspector verwenden, um Tabelleninformationen abzurufen\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Alle Tabellennamen abrufen\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Funktion zur Analyse einer Tabelle\n",
    "def analyze_table(table_name):\n",
    "    print(f\"\\nAnalysiere Tabelle: {table_name}\")\n",
    "    query = f\"SELECT * FROM `{table_name}`\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # Top 10 und restliche Songs basierend auf Popularität separieren\n",
    "    df = df.sort_values(by='Popularity', ascending=False)\n",
    "    top_10 = df.head(10)\n",
    "    rest = df.iloc[10:]\n",
    "    \n",
    "    print(f\"\\nTop 10 Songs in Tabelle '{table_name}':\")\n",
    "    print(top_10.head())\n",
    "    \n",
    "    # Statistische Zusammenfassung der Features\n",
    "    print(f\"\\nStatistische Zusammenfassung der Features in den Top 10:\")\n",
    "    print(top_10.describe())\n",
    "    \n",
    "    print(f\"\\nStatistische Zusammenfassung der Features in den restlichen Songs:\")\n",
    "    print(rest.describe())\n",
    "    \n",
    "    # Verteilung der numerischen Variablen für Top 10 und Rest\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    for column in numerical_columns:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(top_10[column], color='blue', label='Top 10', kde=True, stat='density', bins=15)\n",
    "        sns.histplot(rest[column], color='orange', label='Rest', kde=True, stat='density', bins=15)\n",
    "        plt.legend()\n",
    "        plt.title(f'Verteilung der {column} für Top 10 und restliche Songs in Tabelle {table_name}')\n",
    "        plt.show()\n",
    "    \n",
    "    # Korrelationen zwischen den Features in den Top 10\n",
    "    corr_matrix_top_10 = top_10[numerical_columns].corr()\n",
    "    sns.heatmap(corr_matrix_top_10, annot=True, cmap='coolwarm')\n",
    "    plt.title(f\"Korrelationsmatrix der Features in den Top 10 in Tabelle '{table_name}'\")\n",
    "    plt.show()\n",
    "\n",
    "# Jede Tabelle analysieren\n",
    "for table_name in table_names:\n",
    "    analyze_table(table_name)\n",
    "\n",
    "print(\"\\nAnalyse abgeschlossen.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisse der Analyse\n",
    "\n",
    "Die explorative Datenanalyse (EDA) der drei Excel-Dateien für die Länder Schweiz, Deutschland und Argentinien hat folgende Erkenntnisse geliefert:\n",
    "\n",
    "### Features, die tendenziell höher sind in den Top 10 Songs:\n",
    "\n",
    "- **Popularity:** Offensichtlich haben die Top 10 Songs höhere Popularitätswerte.\n",
    "- **Energy:** Die Top 10 Songs neigen dazu, höhere Energiewerte zu haben.\n",
    "- **Loudness:** Die Lautstärke (loudness) ist in den Top 10 Songs tendenziell höher.\n",
    "- **Valence:** Diese Messung des musikalischen Positivitätslevels zeigt höhere Werte bei den Top 10 Songs.\n",
    "\n",
    "### Verteilungen der Features:\n",
    "\n",
    "- **Danceability:** Die Tanzbarkeit (danceability) zeigt eine tendenziell höhere Verteilung in den Top 10 Songs.\n",
    "- **Tempo:** Das Tempo variiert, aber die Top 10 Songs neigen dazu, spezifische Tempobereiche häufiger zu besetzen.\n",
    "\n",
    "### Korrelationen:\n",
    "\n",
    "Die Korrelationsmatrizen zeigen, wie verschiedene Features miteinander korrelieren. In den Top 10 Songs gibt es oft stärkere Korrelationen zwischen Popularität und anderen Features wie Energy und Loudness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 3: EDA & Modellierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Sensible Daten aus Umgebungsvariablen lesen\n",
    "db_user = os.getenv('DB_USER', 'root')\n",
    "db_password = os.getenv('DB_PASSWORD', 'example')\n",
    "db_host = os.getenv('DB_HOST', 'localhost')\n",
    "db_name = os.getenv('DB_NAME', 'spotify_data')\n",
    "\n",
    "# Verbindung zur MySQL-Datenbank herstellen\n",
    "engine = create_engine(f'mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}')\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Mapping der Länder zu geografischen Daten\n",
    "geographic_data = {\n",
    "    'Argentinien': {'lat': -38.4161, 'lon': -63.6167},\n",
    "    'Australien': {'lat': -25.2744, 'lon': 133.7751},\n",
    "    'Belarus': {'lat': 53.7098, 'lon': 27.9534},\n",
    "    'Belgien': {'lat': 50.5039, 'lon': 4.4699},\n",
    "    'Bolivien': {'lat': -16.2902, 'lon': -63.5887},\n",
    "    'Brasilien': {'lat': -14.2350, 'lon': -51.9253},\n",
    "    'Bulgarien': {'lat': 42.7339, 'lon': 25.4858},\n",
    "    'Chile': {'lat': -35.6751, 'lon': -71.5430},\n",
    "    'Costa Rica': {'lat': 9.7489, 'lon': -83.7534},\n",
    "    'Deutschland': {'lat': 51.1657, 'lon': 10.4515},\n",
    "    'Dominikanische Republik': {'lat': 18.7357, 'lon': -70.1627},\n",
    "    'Dänemark': {'lat': 56.2639, 'lon': 9.5018},\n",
    "    'Ecuador': {'lat': -1.8312, 'lon': -78.1834},\n",
    "    'El Salvador': {'lat': 13.7942, 'lon': -88.8965},\n",
    "    'Estland': {'lat': 58.5953, 'lon': 25.0136},\n",
    "    'Finnland': {'lat': 61.9241, 'lon': 25.7482},\n",
    "    'Frankreich': {'lat': 46.6034, 'lon': 1.8883},\n",
    "    'Griechenland': {'lat': 39.0742, 'lon': 21.8243},\n",
    "    'Grossbritannien': {'lat': 55.3781, 'lon': -3.4360},\n",
    "    'Guatemala': {'lat': 15.7835, 'lon': -90.2308},\n",
    "    'Honduras': {'lat': 15.2000, 'lon': -86.2419},\n",
    "    'Hong Kong': {'lat': 22.3193, 'lon': 114.1694},\n",
    "    'Indien': {'lat': 20.5937, 'lon': 78.9629},\n",
    "    'Indonesien': {'lat': -0.7893, 'lon': 113.9213},\n",
    "    'Irland': {'lat': 53.1424, 'lon': -7.6921},\n",
    "    'Island': {'lat': 64.9631, 'lon': -19.0208},\n",
    "    'Israel': {'lat': 31.0461, 'lon': 34.8516},\n",
    "    'Italien': {'lat': 41.8719, 'lon': 12.5674},\n",
    "    'Japan': {'lat': 36.2048, 'lon': 138.2529},\n",
    "    'Kanada': {'lat': 56.1304, 'lon': -106.3468},\n",
    "    'Kasachstan': {'lat': 48.0196, 'lon': 66.9237},\n",
    "    'Kolumbien': {'lat': 4.5709, 'lon': -74.2973},\n",
    "    'Lettland': {'lat': 56.8796, 'lon': 24.6032},\n",
    "    'Litauen': {'lat': 55.1694, 'lon': 23.8813},\n",
    "    'Luxemburg': {'lat': 49.8153, 'lon': 6.1296},\n",
    "    'Malaysia': {'lat': 4.2105, 'lon': 101.9758},\n",
    "    'Marokko': {'lat': 31.7917, 'lon': -7.0926},\n",
    "    'Mexiko': {'lat': 23.6345, 'lon': -102.5528},\n",
    "    'Neuseeland': {'lat': -40.9006, 'lon': 174.8860},\n",
    "    'Nicaragua': {'lat': 12.8654, 'lon': -85.2072},\n",
    "    'Niederlande': {'lat': 52.1326, 'lon': 5.2913},\n",
    "    'Nigeria': {'lat': 9.0820, 'lon': 8.6753},\n",
    "    'Norwegen': {'lat': 60.4720, 'lon': 8.4689},\n",
    "    'Pakistan': {'lat': 30.3753, 'lon': 69.3451},\n",
    "    'Panama': {'lat': 8.5380, 'lon': -80.7821},\n",
    "    'Paraguay': {'lat': -23.4425, 'lon': -58.4438},\n",
    "    'Peru': {'lat': -9.1900, 'lon': -75.0152},\n",
    "    'Philippinen': {'lat': 12.8797, 'lon': 121.7740},\n",
    "    'Polen': {'lat': 51.9194, 'lon': 19.1451},\n",
    "    'Portugal': {'lat': 39.3999, 'lon': -8.2245},\n",
    "    'Rumänien': {'lat': 45.9432, 'lon': 24.9668},\n",
    "    'Saudi-Arabien': {'lat': 23.8859, 'lon': 45.0792},\n",
    "    'Schweden': {'lat': 60.1282, 'lon': 18.6435},\n",
    "    'Schweiz': {'lat': 46.8182, 'lon': 8.2275},\n",
    "    'Singapur': {'lat': 1.3521, 'lon': 103.8198},\n",
    "    'Slowakei': {'lat': 48.6690, 'lon': 19.6990},\n",
    "    'Spanien': {'lat': 40.4637, 'lon': -3.7492},\n",
    "    'Südafrika': {'lat': -30.5595, 'lon': 22.9375},\n",
    "    'Südkorea': {'lat': 35.9078, 'lon': 127.7669},\n",
    "    'Taiwan': {'lat': 23.6978, 'lon': 120.9605},\n",
    "    'Thailand': {'lat': 15.8700, 'lon': 100.9925},\n",
    "    'Tschechische Republik': {'lat': 49.8175, 'lon': 15.4730},\n",
    "    'Türkei': {'lat': 38.9637, 'lon': 35.2433},\n",
    "    'Ukraine': {'lat': 48.3794, 'lon': 31.1656},\n",
    "    'Ungarn': {'lat': 47.1625, 'lon': 19.5033},\n",
    "    'Uruguay': {'lat': -32.5228, 'lon': -55.7658},\n",
    "    'USA': {'lat': 37.0902, 'lon': -95.7129},\n",
    "    'Venezuela': {'lat': 6.4238, 'lon': -66.5897},\n",
    "    'Vereinigte Arabische Emirate': {'lat': 23.4241, 'lon': 53.8478},\n",
    "    'Vietnam': {'lat': 14.0583, 'lon': 108.2772},\n",
    "    'Ägypten': {'lat': 26.8206, 'lon': 30.8025},\n",
    "    'Österreich': {'lat': 47.5162, 'lon': 14.5501},\n",
    "}\n",
    "\n",
    "# Funktion zur Analyse und Vorbereitung der Daten\n",
    "def prepare_data(engine, table_names):\n",
    "    combined_data = []\n",
    "    for table_name in table_names:\n",
    "        df = pd.read_sql(f\"SELECT * FROM `{table_name}`\", engine)\n",
    "        country_name = ' '.join(table_name.split(' ')[2:-1]).strip('–').strip()  # Extrahiere den vollständigen Ländernamen aus dem Tabellennamen und trimme Leerzeichen\n",
    "        if country_name in geographic_data:\n",
    "            df['Country'] = country_name\n",
    "            df['Lat'] = geographic_data[country_name]['lat']\n",
    "            df['Lon'] = geographic_data[country_name]['lon']\n",
    "            combined_data.append(df)\n",
    "        else:\n",
    "            print(f\"Unknown country code: {country_name} in table: {table_name}\")\n",
    "    if not combined_data:\n",
    "        raise ValueError(\"No valid data to process. Please check the table names and geographic_data mapping.\")\n",
    "    combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Versuchen Sie die Daten zu laden und bei Fehlern fortfahren\n",
    "try:\n",
    "    data = prepare_data(engine, table_names)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "# Explorative Datenanalyse (EDA)\n",
    "def eda(data):\n",
    "    # Distribution of Popularity\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data['Popularity'], kde=True, bins=20)\n",
    "    plt.title('Distribution of Popularity')\n",
    "    plt.show()\n",
    "    \n",
    "    # Pairplot of numerical features\n",
    "    numerical_columns = ['danceability', 'energy', 'loudness', 'valence', 'tempo']\n",
    "    sns.pairplot(data[numerical_columns + ['Popularity']], diag_kind='kde')\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr_matrix = data[numerical_columns + ['Popularity']].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n",
    "\n",
    "if 'data' in locals():\n",
    "    eda(data)\n",
    "\n",
    "    # Datenvorbereitung\n",
    "    def preprocess_data(data):\n",
    "        # Features und Zielvariable definieren\n",
    "        features = ['danceability', 'energy', 'loudness', 'valence', 'tempo', 'Lat', 'Lon']\n",
    "        target = data['Popularity']\n",
    "        \n",
    "        X = data[features]\n",
    "        y = (target >= target.nlargest(10).min()).astype(int)  # Binary target: 1 if in Top 10, else 0\n",
    "        \n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "\n",
    "    # Deep Learning Modell mit Keras\n",
    "    def build_model(input_shape):\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=input_shape),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    model = build_model(input_shape)\n",
    "\n",
    "    # Modell trainieren\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Modellvorhersagen\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Evaluation der Modelle\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Plot training history\n",
    "    def plot_history(history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='loss')\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Model Loss')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Model Accuracy')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    plot_history(history)\n",
    "\n",
    "    # Bestimmung der wichtigsten Features für jedes Land\n",
    "    def get_top_features_per_country(data):\n",
    "        top_features = {}\n",
    "        for country, group in data.groupby('Country'):\n",
    "            top_songs = group.nlargest(10, 'Popularity')\n",
    "            feature_means = top_songs[['danceability', 'energy', 'loudness', 'valence', 'tempo']].mean()\n",
    "            top_features[country] = feature_means.nlargest(3).index.tolist()\n",
    "        return top_features\n",
    "\n",
    "    top_features_per_country = get_top_features_per_country(data)\n",
    "    \n",
    "    # Weltkarte mit den wichtigsten Features\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "    # Umwandlung der geografischen Daten in ein GeoDataFrame\n",
    "    geo_data = []\n",
    "    for country, coords in geographic_data.items():\n",
    "        if country in top_features_per_country:\n",
    "            features = ', '.join(top_features_per_country[country])\n",
    "            geo_data.append({'Country': country, 'Lat': coords['lat'], 'Lon': coords['lon'], 'Top Features': features})\n",
    "    \n",
    "    geo_df = pd.DataFrame(geo_data)\n",
    "    geo_gdf = gpd.GeoDataFrame(geo_df, geometry=gpd.points_from_xy(geo_df.Lon, geo_df.Lat))\n",
    "\n",
    "    # Plot der Weltkarte\n",
    "    def plot_map(geo_gdf, title, bounds=None):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        ax.coastlines(color='#A9A9A9')\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle='-', edgecolor='#A9A9A9')\n",
    "        ax.add_feature(cfeature.LAND, facecolor='#A8E4A0')\n",
    "        ax.add_feature(cfeature.OCEAN, facecolor='#89CFF0')\n",
    "        \n",
    "        # Annotieren der wichtigsten Features für jedes Land\n",
    "        for x, y, label in zip(geo_gdf.geometry.x, geo_gdf.geometry.y, geo_gdf['Top Features']):\n",
    "            ax.text(x, y, label, fontsize=8, transform=ccrs.PlateCarree())\n",
    "        \n",
    "        geo_gdf.plot(ax=ax, color='#EA899A', markersize=50, label='Top Features', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        if bounds:\n",
    "            ax.set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Plot der globalen Karte\n",
    "    plot_map(geo_gdf, 'Top 3 Features for Each Country - Global')\n",
    "\n",
    "    # Regionen plotten\n",
    "    regions = {\n",
    "        'Europe': ['Deutschland', 'Frankreich', 'Grossbritannien', 'Spanien', 'Italien', 'Schweiz', 'Niederlande', 'Belgien', 'Österreich', 'Schweden', 'Dänemark', 'Norwegen', 'Finnland', 'Irland', 'Portugal', 'Griechenland', 'Tschechische Republik', 'Polen', 'Ungarn', 'Rumänien', 'Bulgarien', 'Estland', 'Lettland', 'Litauen', 'Luxemburg', 'Slowakei'],\n",
    "        'Oceania': ['Australien', 'Neuseeland'],\n",
    "        'Asia': ['Japan', 'Indien', 'Indonesien', 'Israel', 'Hong Kong', 'Südkorea', 'Taiwan', 'Malaysia', 'Thailand', 'Philippinen', 'Pakistan', 'Kasachstan', 'Vereinigte Arabische Emirate', 'Saudi-Arabien', 'Vietnam'],\n",
    "        'South America': ['Argentinien', 'Brasilien', 'Chile', 'Kolumbien', 'Ecuador', 'Peru', 'Bolivien', 'Paraguay', 'Uruguay', 'Venezuela'],\n",
    "        'North America': ['Kanada', 'USA'],\n",
    "        'Central America': ['Mexiko', 'Guatemala', 'Honduras', 'El Salvador', 'Panama', 'Costa Rica', 'Nicaragua'],\n",
    "        'Africa': ['Nigeria', 'Südafrika', 'Marokko', 'Ägypten']\n",
    "    }\n",
    "\n",
    "    region_bounds = {\n",
    "        'Europe': [-31.266, 39.869, 32.878, 81.008],\n",
    "        'Oceania': [110, 180, -50, 0],\n",
    "        'Asia': [60, 150, -10, 55],\n",
    "        'South America': [-82, -34, -55, 13],\n",
    "        'North America': [-170, -50, 5, 83],\n",
    "        'Central America': [-120, -75, 0, 30],\n",
    "        'Africa': [-30, 60, -35, 40]\n",
    "    }\n",
    "\n",
    "    for region, countries in regions.items():\n",
    "        regional_geo_gdf = geo_gdf[geo_gdf['Country'].isin(countries)]\n",
    "        plot_map(regional_geo_gdf, f'Top 3 Features for Each Country - {region}', bounds=region_bounds[region])\n",
    "\n",
    "    # Balkendiagramm der wichtigsten Features pro Land\n",
    "    def plot_top_features_bar(top_features_per_country):\n",
    "        feature_counts = {feature: [] for feature in ['danceability', 'energy', 'loudness', 'valence', 'tempo']}\n",
    "        \n",
    "        for country, features in top_features_per_country.items():\n",
    "            for feature in feature_counts.keys():\n",
    "                feature_counts[feature].append(features.count(feature))\n",
    "        \n",
    "        feature_df = pd.DataFrame(feature_counts, index=top_features_per_country.keys())\n",
    "        \n",
    "        feature_df.plot(kind='bar', stacked=True, figsize=(15, 10))\n",
    "        plt.title('Top Features for Each Country')\n",
    "        plt.xlabel('Country')\n",
    "        plt.ylabel('Number of Top Features')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend(title='Top Features')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_top_features_bar(top_features_per_country)\n",
    "\n",
    "    # Heatmap der wichtigsten Features pro Land\n",
    "    def plot_top_features_heatmap(top_features_per_country):\n",
    "        feature_presence = {feature: [] for feature in ['danceability', 'energy', 'loudness', 'valence', 'tempo']}\n",
    "        \n",
    "        for country, features in top_features_per_country.items():\n",
    "            for feature in feature_presence.keys():\n",
    "                feature_presence[feature].append(1 if feature in features else 0)\n",
    "        \n",
    "        feature_df = pd.DataFrame(feature_presence, index=top_features_per_country.keys())\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(feature_df, annot=True, cmap=\"YlGnBu\", cbar=False)\n",
    "        plt.title('Heatmap of Top Features for Each Country')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Country')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_top_features_heatmap(top_features_per_country)\n",
    "\n",
    "else:\n",
    "    print(\"No valid data found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Datenanalyse (EDA)\n",
    "\n",
    "### Verteilung der Popularität\n",
    "\n",
    "Der erste Plot zeigt die Verteilung der Popularität von Songs. Die meisten Songs haben eine hohe Popularität, wobei der Großteil der Popularitätswerte zwischen 60 und 100 liegt.\n",
    "\n",
    "### Pairplot der numerischen Features\n",
    "\n",
    "Dieser Plot zeigt die paarweise Verteilung der numerischen Features (danceability, energy, loudness, valence, tempo) und ihre Beziehung zur Popularität.\n",
    "- Die Diagonalen zeigen die Verteilungen der einzelnen Features, während die Scatterplots die Beziehungen zwischen den Features darstellen.\n",
    "\n",
    "### Korrelationsmatrix\n",
    "\n",
    "Dieser Heatmap-Plot zeigt die Korrelationen zwischen den numerischen Features und der Popularität.\n",
    "- Ein hoher positiver Wert (nahe 1) zeigt eine starke positive Korrelation, ein hoher negativer Wert (nahe -1) zeigt eine starke negative Korrelation und ein Wert nahe 0 zeigt keine Korrelation.\n",
    "- Laut der Korrelationsmatrix haben loudness und energy die höchste Korrelation (0.72). Die Korrelationen der Features mit der Popularität sind alle relativ niedrig.\n",
    "\n",
    "## Modelltraining und -bewertung\n",
    "\n",
    "### Modelltraining\n",
    "\n",
    "Das Modell wurde über 50 Epochen trainiert, wobei die Loss- und Accuracy-Werte für Trainings- und Validierungsdatensätze pro Epoche angezeigt wurden.\n",
    "- Der Verlust (Loss) sinkt kontinuierlich und die Genauigkeit (Accuracy) steigt, was auf eine Verbesserung des Modells mit jeder Epoche hinweist.\n",
    "\n",
    "### Modellvorhersagen und Klassifikationsbericht\n",
    "\n",
    "Die Ausgabe zeigt den Klassifikationsbericht, einschließlich Präzision, Recall und F1-Score für jede Klasse (0 und 1).\n",
    "- Die Confusion-Matrix zeigt die Anzahl der True Positives, True Negatives, False Positives und False Negatives.\n",
    "- Das Modell scheint sehr hohe Präzisions-, Recall- und F1-Score-Werte zu haben, was auf eine hervorragende Leistung hinweist.\n",
    "\n",
    "### Plot der Trainingsgeschichte\n",
    "\n",
    "Zwei Plots zeigen die Entwicklung des Verlusts (Loss) und der Genauigkeit (Accuracy) über die Epochen.\n",
    "- Der Verlust sinkt und stabilisiert sich, während die Genauigkeit steigt und sich ebenfalls stabilisiert.\n",
    "\n",
    "## Interpretation der Ergebnisse\n",
    "\n",
    "### Verteilung der Popularität\n",
    "\n",
    "- Die meisten Songs in den Daten haben eine hohe Popularität. Es gibt wenige Songs mit niedriger Popularität.\n",
    "\n",
    "### Pairplot und Korrelationsmatrix\n",
    "\n",
    "- Es gibt moderate Korrelationen zwischen bestimmten Features wie loudness und energy.\n",
    "- Die Korrelationen der Features mit der Popularität sind alle relativ gering, was darauf hinweist, dass die Popularität nicht stark von einem einzelnen Feature abhängt, sondern möglicherweise eine Kombination mehrerer Features relevant ist.\n",
    "\n",
    "### Modellleistung\n",
    "\n",
    "- Das Modell zeigt eine sehr hohe Leistung, was durch die hohen Werte für Präzision, Recall und F1-Score unterstützt wird.\n",
    "- Die Loss- und Accuracy-Plots zeigen, dass das Modell gut konvergiert ist und keine Anzeichen von Overfitting zeigt, da die Validierungsgenauigkeit hoch bleibt und der Validierungsverlust niedrig ist.\n",
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "- Die explorative Datenanalyse zeigt wichtige Beziehungen und Verteilungen der Features.\n",
    "- Das trainierte Modell zeigt eine ausgezeichnete Leistung bei der Vorhersage der Popularität von Songs basierend auf den gegebenen Features.\n",
    "- Die Ergebnisse sind vielversprechend, und das Modell könnte potenziell verwendet werden, um zukünftige Song-Popularitäten vorherzusagen oder Einblicke in die Faktoren zu geben, die die Popularität beeinflussen.\n",
    "\n",
    "\n",
    "## Erklärung der Heatmap\n",
    "\n",
    "Die Heatmap zeigt die Präsenz der wichtigsten Features in den Top-Songs jedes Landes. Hier sind die Details der Visualisierung:\n",
    "\n",
    "### Achsen\n",
    "\n",
    "- **Vertikale Achse (Y-Achse):** Zeigt die Namen der Länder an.\n",
    "- **Horizontale Achse (X-Achse):** Zeigt die verschiedenen musikalischen Features (danceability, energy, loudness, valence, tempo).\n",
    "\n",
    "### Farben\n",
    "\n",
    "- **Dunkelblau (Wert 1):** Bedeutet, dass dieses Feature zu den Top 3 Features in den Top-Songs des jeweiligen Landes gehört.\n",
    "- **Hellgelb (Wert 0):** Bedeutet, dass dieses Feature nicht zu den Top 3 Features in den Top-Songs des jeweiligen Landes gehört.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Danceability (Tanzbarkeit):** Fast alle Länder zeigen, dass Tanzbarkeit ein wichtiges Feature ist, was durch die durchgehenden dunkelblauen Balken in der ersten Spalte angezeigt wird.\n",
    "- **Energy (Energie):** In den meisten Ländern ist Energie kein Top-Feature, was durch die überwiegend hellgelben Balken in der zweiten Spalte angezeigt wird. Ausnahmen sind Indonesien, Nigeria, und Österreich, wo Energie ein wichtiges Feature ist.\n",
    "- **Loudness (Lautstärke):** In keinem der Länder ist Lautstärke ein Top-Feature, was durch die durchgehenden hellgelben Balken in der dritten Spalte angezeigt wird.\n",
    "- **Valence (Valenz):** In keinem der Länder ist Valenz ein Top-Feature, was durch die durchgehenden hellgelben Balken in der vierten Spalte angezeigt wird.\n",
    "- **Tempo:** In allen Ländern ist Tempo ein wichtiges Feature, was durch die durchgehenden dunkelblauen Balken in der fünften Spalte angezeigt wird.\n",
    "\n",
    "### Schlussfolgerungen\n",
    "\n",
    "- **Globale Trends:** Tanzbarkeit und Tempo sind die am häufigsten vorkommenden Features in den Top-Songs der verschiedenen Länder.\n",
    "- **Regionale Unterschiede:** Einige Länder haben Energie als wichtiges Feature (z.B. Indonesien, Nigeria, Österreich), während andere Länder diese Merkmale weniger wichtig finden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gleicher Code wie oben mit Vorhersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Sensible Daten aus Umgebungsvariablen lesen\n",
    "db_user = os.getenv('DB_USER', 'root')\n",
    "db_password = os.getenv('DB_PASSWORD', 'example')\n",
    "db_host = os.getenv('DB_HOST', 'localhost')\n",
    "db_name = os.getenv('DB_NAME', 'spotify_data')\n",
    "\n",
    "# Verbindung zur MySQL-Datenbank herstellen\n",
    "engine = create_engine(f'mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}')\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Mapping der Länder zu geografischen Daten\n",
    "geographic_data = {\n",
    "    'Argentinien': {'lat': -38.4161, 'lon': -63.6167},\n",
    "    'Australien': {'lat': -25.2744, 'lon': 133.7751},\n",
    "    'Belarus': {'lat': 53.7098, 'lon': 27.9534},\n",
    "    'Belgien': {'lat': 50.5039, 'lon': 4.4699},\n",
    "    'Bolivien': {'lat': -16.2902, 'lon': -63.5887},\n",
    "    'Brasilien': {'lat': -14.2350, 'lon': -51.9253},\n",
    "    'Bulgarien': {'lat': 42.7339, 'lon': 25.4858},\n",
    "    'Chile': {'lat': -35.6751, 'lon': -71.5430},\n",
    "    'Costa Rica': {'lat': 9.7489, 'lon': -83.7534},\n",
    "    'Deutschland': {'lat': 51.1657, 'lon': 10.4515},\n",
    "    'Dominikanische Republik': {'lat': 18.7357, 'lon': -70.1627},\n",
    "    'Dänemark': {'lat': 56.2639, 'lon': 9.5018},\n",
    "    'Ecuador': {'lat': -1.8312, 'lon': -78.1834},\n",
    "    'El Salvador': {'lat': 13.7942, 'lon': -88.8965},\n",
    "    'Estland': {'lat': 58.5953, 'lon': 25.0136},\n",
    "    'Finnland': {'lat': 61.9241, 'lon': 25.7482},\n",
    "    'Frankreich': {'lat': 46.6034, 'lon': 1.8883},\n",
    "    'Griechenland': {'lat': 39.0742, 'lon': 21.8243},\n",
    "    'Grossbritannien': {'lat': 55.3781, 'lon': -3.4360},\n",
    "    'Guatemala': {'lat': 15.7835, 'lon': -90.2308},\n",
    "    'Honduras': {'lat': 15.2000, 'lon': -86.2419},\n",
    "    'Hong Kong': {'lat': 22.3193, 'lon': 114.1694},\n",
    "    'Indien': {'lat': 20.5937, 'lon': 78.9629},\n",
    "    'Indonesien': {'lat': -0.7893, 'lon': 113.9213},\n",
    "    'Irland': {'lat': 53.1424, 'lon': -7.6921},\n",
    "    'Island': {'lat': 64.9631, 'lon': -19.0208},\n",
    "    'Israel': {'lat': 31.0461, 'lon': 34.8516},\n",
    "    'Italien': {'lat': 41.8719, 'lon': 12.5674},\n",
    "    'Japan': {'lat': 36.2048, 'lon': 138.2529},\n",
    "    'Kanada': {'lat': 56.1304, 'lon': -106.3468},\n",
    "    'Kasachstan': {'lat': 48.0196, 'lon': 66.9237},\n",
    "    'Kolumbien': {'lat': 4.5709, 'lon': -74.2973},\n",
    "    'Lettland': {'lat': 56.8796, 'lon': 24.6032},\n",
    "    'Litauen': {'lat': 55.1694, 'lon': 23.8813},\n",
    "    'Luxemburg': {'lat': 49.8153, 'lon': 6.1296},\n",
    "    'Malaysia': {'lat': 4.2105, 'lon': 101.9758},\n",
    "    'Marokko': {'lat': 31.7917, 'lon': -7.0926},\n",
    "    'Mexiko': {'lat': 23.6345, 'lon': -102.5528},\n",
    "    'Neuseeland': {'lat': -40.9006, 'lon': 174.8860},\n",
    "    'Nicaragua': {'lat': 12.8654, 'lon': -85.2072},\n",
    "    'Niederlande': {'lat': 52.1326, 'lon': 5.2913},\n",
    "    'Nigeria': {'lat': 9.0820, 'lon': 8.6753},\n",
    "    'Norwegen': {'lat': 60.4720, 'lon': 8.4689},\n",
    "    'Pakistan': {'lat': 30.3753, 'lon': 69.3451},\n",
    "    'Panama': {'lat': 8.5380, 'lon': -80.7821},\n",
    "    'Paraguay': {'lat': -23.4425, 'lon': -58.4438},\n",
    "    'Peru': {'lat': -9.1900, 'lon': -75.0152},\n",
    "    'Philippinen': {'lat': 12.8797, 'lon': 121.7740},\n",
    "    'Polen': {'lat': 51.9194, 'lon': 19.1451},\n",
    "    'Portugal': {'lat': 39.3999, 'lon': -8.2245},\n",
    "    'Rumänien': {'lat': 45.9432, 'lon': 24.9668},\n",
    "    'Saudi-Arabien': {'lat': 23.8859, 'lon': 45.0792},\n",
    "    'Schweden': {'lat': 60.1282, 'lon': 18.6435},\n",
    "    'Schweiz': {'lat': 46.8182, 'lon': 8.2275},\n",
    "    'Singapur': {'lat': 1.3521, 'lon': 103.8198},\n",
    "    'Slowakei': {'lat': 48.6690, 'lon': 19.6990},\n",
    "    'Spanien': {'lat': 40.4637, 'lon': -3.7492},\n",
    "    'Südafrika': {'lat': -30.5595, 'lon': 22.9375},\n",
    "    'Südkorea': {'lat': 35.9078, 'lon': 127.7669},\n",
    "    'Taiwan': {'lat': 23.6978, 'lon': 120.9605},\n",
    "    'Thailand': {'lat': 15.8700, 'lon': 100.9925},\n",
    "    'Tschechische Republik': {'lat': 49.8175, 'lon': 15.4730},\n",
    "    'Türkei': {'lat': 38.9637, 'lon': 35.2433},\n",
    "    'Ukraine': {'lat': 48.3794, 'lon': 31.1656},\n",
    "    'Ungarn': {'lat': 47.1625, 'lon': 19.5033},\n",
    "    'Uruguay': {'lat': -32.5228, 'lon': -55.7658},\n",
    "    'USA': {'lat': 37.0902, 'lon': -95.7129},\n",
    "    'Venezuela': {'lat': 6.4238, 'lon': -66.5897},\n",
    "    'Vereinigte Arabische Emirate': {'lat': 23.4241, 'lon': 53.8478},\n",
    "    'Vietnam': {'lat': 14.0583, 'lon': 108.2772},\n",
    "    'Ägypten': {'lat': 26.8206, 'lon': 30.8025},\n",
    "    'Österreich': {'lat': 47.5162, 'lon': 14.5501},\n",
    "}\n",
    "\n",
    "# Funktion zur Analyse und Vorbereitung der Daten\n",
    "def prepare_data(engine, table_names):\n",
    "    combined_data = []\n",
    "    for table_name in table_names:\n",
    "        df = pd.read_sql(f\"SELECT * FROM `{table_name}`\", engine)\n",
    "        country_name = ' '.join(table_name.split(' ')[2:-1]).strip('–').strip()  # Extrahiere den vollständigen Ländernamen aus dem Tabellennamen und trimme Leerzeichen\n",
    "        if country_name in geographic_data:\n",
    "            df['Country'] = country_name\n",
    "            df['Lat'] = geographic_data[country_name]['lat']\n",
    "            df['Lon'] = geographic_data[country_name]['lon']\n",
    "            combined_data.append(df)\n",
    "        else:\n",
    "            print(f\"Unknown country code: {country_name} in table: {table_name}\")\n",
    "    if not combined_data:\n",
    "        raise ValueError(\"No valid data to process. Please check the table names and geographic_data mapping.\")\n",
    "    combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Versuchen Sie die Daten zu laden und bei Fehlern fortfahren\n",
    "try:\n",
    "    data = prepare_data(engine, table_names)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "# Explorative Datenanalyse (EDA)\n",
    "def eda(data):\n",
    "    numerical_columns = ['danceability', 'energy', 'loudness', 'valence', 'tempo']\n",
    "    \n",
    "    # Distribution of Popularity\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data['Popularity'], kde=True, bins=20)\n",
    "    plt.title('Distribution of Popularity')\n",
    "    plt.show()\n",
    "    \n",
    "    # Pairplot of numerical features\n",
    "    sns.pairplot(data[numerical_columns + ['Popularity']], diag_kind='kde')\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr_matrix = data[numerical_columns + ['Popularity']].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    return numerical_columns\n",
    "\n",
    "if 'data' in locals():\n",
    "    numerical_columns = eda(data)\n",
    "\n",
    "    # Datenvorbereitung\n",
    "    def preprocess_data(data, numerical_columns):\n",
    "        # Features und Zielvariable definieren\n",
    "        features = numerical_columns + ['Lat', 'Lon']\n",
    "        target = data['Popularity']\n",
    "        \n",
    "        X = data[features]\n",
    "        y = (target >= target.nlargest(10).min()).astype(int)  # Binary target: 1 if in Top 10, else 0\n",
    "        \n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data, numerical_columns)\n",
    "\n",
    "    # Deep Learning Modell mit Keras\n",
    "    def build_model(input_shape):\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=input_shape),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    model = build_model(input_shape)\n",
    "\n",
    "    # Modell trainieren\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Modellvorhersagen\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Evaluation der Modelle\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Plot training history\n",
    "    def plot_history(history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='loss')\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Model Loss')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Model Accuracy')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    plot_history(history)\n",
    "\n",
    "    # Bestimmung der wichtigsten Features für jedes Land\n",
    "    def get_top_features_per_country(data, numerical_columns):\n",
    "        top_features = {}\n",
    "        for country, group in data.groupby('Country'):\n",
    "            top_songs = group.nlargest(10, 'Popularity')\n",
    "            feature_means = top_songs[numerical_columns].mean()\n",
    "            top_features[country] = feature_means.nlargest(3).index.tolist()\n",
    "        return top_features\n",
    "\n",
    "    top_features_per_country = get_top_features_per_country(data, numerical_columns)\n",
    "    \n",
    "    # Weltkarte mit den wichtigsten Features\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "    # Umwandlung der geografischen Daten in ein GeoDataFrame\n",
    "    geo_data = []\n",
    "    for country, coords in geographic_data.items():\n",
    "        if country in top_features_per_country:\n",
    "            features = ', '.join(top_features_per_country[country])\n",
    "            geo_data.append({'Country': country, 'Lat': coords['lat'], 'Lon': coords['lon'], 'Top Features': features})\n",
    "    \n",
    "    geo_df = pd.DataFrame(geo_data)\n",
    "    geo_gdf = gpd.GeoDataFrame(geo_df, geometry=gpd.points_from_xy(geo_df.Lon, geo_df.Lat))\n",
    "\n",
    "    # Plot der Weltkarte\n",
    "    def plot_map(geo_gdf, title, bounds=None):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        ax.coastlines(color='#A9A9A9')\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle='-', edgecolor='#A9A9A9')\n",
    "        ax.add_feature(cfeature.LAND, facecolor='#A8E4A0')\n",
    "        ax.add_feature(cfeature.OCEAN, facecolor='#89CFF0')\n",
    "        \n",
    "        # Annotieren der wichtigsten Features für jedes Land\n",
    "        for x, y, label in zip(geo_gdf.geometry.x, geo_gdf.geometry.y, geo_gdf['Top Features']):\n",
    "            ax.text(x, y, label, fontsize=8, ha='right', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        geo_gdf.plot(ax=ax, color='#EA899A', markersize=50, label='Top Features', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        if bounds:\n",
    "            ax.set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Plot der globalen Karte\n",
    "    plot_map(geo_gdf, 'Top 3 Features for Each Country - Global')\n",
    "\n",
    "    # Regionen plotten\n",
    "    regions = {\n",
    "        'Europe': ['Deutschland', 'Frankreich', 'Grossbritannien', 'Spanien', 'Italien', 'Schweiz', 'Niederlande', 'Belgien', 'Österreich', 'Schweden', 'Dänemark', 'Norwegen', 'Finnland', 'Irland', 'Portugal', 'Griechenland', 'Tschechische Republik', 'Polen', 'Ungarn', 'Rumänien', 'Bulgarien', 'Estland', 'Lettland', 'Litauen', 'Luxemburg', 'Slowakei'],\n",
    "        'Oceania': ['Australien', 'Neuseeland'],\n",
    "        'Asia': ['Japan', 'Indien', 'Indonesien', 'Israel', 'Hong Kong', 'Südkorea', 'Taiwan', 'Malaysia', 'Thailand', 'Philippinen', 'Pakistan', 'Kasachstan', 'Vereinigte Arabische Emirate', 'Saudi-Arabien', 'Vietnam'],\n",
    "        'South America': ['Argentinien', 'Brasilien', 'Chile', 'Kolumbien', 'Ecuador', 'Peru', 'Bolivien', 'Paraguay', 'Uruguay', 'Venezuela'],\n",
    "        'North America': ['Kanada', 'USA'],\n",
    "        'Central America': ['Mexiko', 'Guatemala', 'Honduras', 'El Salvador', 'Panama', 'Costa Rica', 'Nicaragua'],\n",
    "        'Africa': ['Nigeria', 'Südafrika', 'Marokko', 'Ägypten']\n",
    "    }\n",
    "\n",
    "    region_bounds = {\n",
    "        'Europe': [-31.266, 39.869, 32.878, 81.008],\n",
    "        'Oceania': [110, 180, -50, 0],\n",
    "        'Asia': [60, 150, -10, 55],\n",
    "        'South America': [-82, -34, -55, 13],\n",
    "        'North America': [-170, -50, 5, 83],\n",
    "        'Central America': [-120, -75, 0, 30],\n",
    "        'Africa': [-30, 60, -35, 40]\n",
    "    }\n",
    "\n",
    "    for region, countries in regions.items():\n",
    "        regional_geo_gdf = geo_gdf[geo_gdf['Country'].isin(countries)]\n",
    "        plot_map(regional_geo_gdf, f'Top 3 Features for Each Country - {region}', bounds=region_bounds[region])\n",
    "\n",
    "    # Balkendiagramm der wichtigsten Features pro Land\n",
    "    def plot_top_features_bar(top_features_per_country):\n",
    "        feature_counts = {feature: [] for feature in ['danceability', 'energy', 'loudness', 'valence', 'tempo']}\n",
    "        \n",
    "        for country, features in top_features_per_country.items():\n",
    "            for feature in feature_counts.keys():\n",
    "                feature_counts[feature].append(features.count(feature))\n",
    "        \n",
    "        feature_df = pd.DataFrame(feature_counts, index=top_features_per_country.keys())\n",
    "        \n",
    "        feature_df.plot(kind='bar', stacked=True, figsize=(15, 10))\n",
    "        plt.title('Top Features for Each Country')\n",
    "        plt.xlabel('Country')\n",
    "        plt.ylabel('Number of Top Features')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend(title='Top Features')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_top_features_bar(top_features_per_country)\n",
    "\n",
    "    # Heatmap der wichtigsten Features pro Land\n",
    "    def plot_top_features_heatmap(top_features_per_country):\n",
    "        feature_presence = {feature: [] for feature in ['danceability', 'energy', 'loudness', 'valence', 'tempo']}\n",
    "        \n",
    "        for country, features in top_features_per_country.items():\n",
    "            for feature in feature_presence.keys():\n",
    "                feature_presence[feature].append(1 if feature in features else 0)\n",
    "        \n",
    "        feature_df = pd.DataFrame(feature_presence, index=top_features_per_country.keys())\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(feature_df, annot=True, cmap=\"YlGnBu\", cbar=False, linewidths=0.5, linecolor='black')\n",
    "        plt.title('Heatmap of Top Features for Each Country')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Country')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_top_features_heatmap(top_features_per_country)\n",
    "\n",
    "    # Überprüfung der Normalverteilung\n",
    "    for feature in numerical_columns:\n",
    "        stat, p = shapiro(data[feature])\n",
    "        print(f'{feature}: p-value = {p}')\n",
    "        if p > 0.05:\n",
    "            print(f'{feature} seems to be normally distributed (fail to reject H0)')\n",
    "        else:\n",
    "            print(f'{feature} is not normally distributed (reject H0)')\n",
    "    \n",
    "    # Überprüfung der Multikollinearität\n",
    "    X = data[numerical_columns]\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "    print(vif_data)\n",
    "    \n",
    "    # Überprüfung der linearen Beziehungen\n",
    "    for feature in numerical_columns:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.scatterplot(data=data, x=feature, y='Popularity')\n",
    "        plt.title(f'{feature} vs Popularity')\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No valid data found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellierungshypothesen und Überprüfung der Annahmen\n",
    "\n",
    "## 1. Formulierung von Modellierungshypothesen\n",
    "\n",
    "### Hypothese 1:\n",
    "\n",
    "**Feature-Korrelationen beeinflussen die Vorhersage der Song-Popularität.**\n",
    "\n",
    "- **Annahme:** Die Popularität eines Songs wird stark von Features wie Tanzbarkeit, Energie, Lautstärke, Valenz und Tempo beeinflusst.\n",
    "\n",
    "### Hypothese 2:\n",
    "\n",
    "**Geografische Merkmale (Latitude und Longitude) haben einen Einfluss auf die Top-Features der Songs in verschiedenen Ländern.**\n",
    "\n",
    "- **Annahme:** Unterschiedliche Regionen haben unterschiedliche musikalische Vorlieben, die sich in den Top-Features der Songs widerspiegeln.\n",
    "\n",
    "## 2. Überprüfung von Modellierungsannahmen\n",
    "\n",
    "### Annahme 1: Normalverteilung der Features\n",
    "\n",
    "Überprüfung, ob die Features normalverteilt sind.\n",
    "\n",
    "### Annahme 2: Multikollinearität der Features\n",
    "\n",
    "Überprüfung der Multikollinearität der Features mittels Variance Inflation Factor (VIF).\n",
    "\n",
    "### Annahme 3: Lineare Beziehungen zwischen Features und Zielvariable\n",
    "\n",
    "Überprüfung der linearen Beziehungen zwischen den Features und der Zielvariable (Popularität).\n",
    "\n",
    "## Erklärung der Heatmap\n",
    "Die Heatmap visualisiert, welche Features für jedes Land am wichtigsten sind. Die Spalten repräsentieren die Features (z.B. Tanzbarkeit, Energie, Lautstärke, Valenz und Tempo) und die Zeilen repräsentieren die Länder. Ein Wert von 1 bedeutet, dass das Feature zu den Top-3-Features des jeweiligen Landes gehört, während 0 bedeutet, dass es nicht zu den Top-3-Features gehört.\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "Dunkelblau zeigt an, dass das Feature nicht zu den Top-3-Features gehört.\n",
    "Hellgelb zeigt an, dass das Feature zu den Top-3-Features gehört.\n",
    "Durch die Heatmap können wir schnell erkennen, welche Features in welchen Ländern besonders wichtig sind.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gleicher Code wie oben mit NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erklärung der Schritte\n",
    "Datenvorbereitung und EDA:\n",
    "\n",
    "Der Code lädt die Daten aus der Datenbank und führt eine explorative Datenanalyse (EDA) durch.\n",
    "Modelltraining und -vorhersagen:\n",
    "\n",
    "Ein Deep-Learning-Modell wird mit den Audio-Features der Songs trainiert, um vorherzusagen, ob ein Song in den Top 10 landet oder nicht.\n",
    "Geografische Visualisierungen:\n",
    "\n",
    "Eine globale und regionale Kartenvisualisierung zeigt die wichtigsten Audio-Features für jedes Land.\n",
    "NLP-Integration:\n",
    "\n",
    "Sentiment-Analyse der Songtitel wird durchgeführt und visualisiert.\n",
    "Eine Häufigkeitsanalyse und Wortwolke der Songtitel werden erstellt.\n",
    "Themenmodellierung (LDA) wird auf die Songtitel angewendet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads-spotify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
